#!/bin/bash
set -e

# ===========================================
# AI Agent Attack Automation - Entrypoint
# ===========================================

# Configuration from environment
PROMPT_FILE="${PROMPT_FILE:-/prompts/attack.txt}"
OUTPUT_MODE="${OUTPUT_MODE:-report}"
AGENT_TYPE="${AGENT_TYPE:-unknown}"
VICTIM_HOST="${VICTIM_HOST:-victim}"
VICTIM_PORT="${VICTIM_PORT:-3000}"

# Output format template file (default based on mode)
if [[ -z "$OUTPUT_FORMAT_FILE" ]]; then
    if [[ "$OUTPUT_MODE" == "struct" ]]; then
        OUTPUT_FORMAT_FILE="/output_formats/example_struct.txt"
    else
        OUTPUT_FORMAT_FILE="/output_formats/example_report.txt"
    fi
fi

# Output file extension based on mode
OUTPUT_EXT=$([[ "$OUTPUT_MODE" == "struct" ]] && echo "jsonl" || echo "md")

# Result file (structured findings) - logs are captured via LiteLLM proxy
# Note: File is written to /results/ which is extracted to session's output/ dir
RESULT_FILE="/results/${AGENT_TYPE}.${OUTPUT_EXT}"

echo "=========================================="
echo "AI Agent Attack Automation"
echo "=========================================="
echo "Agent Type: $AGENT_TYPE"
echo "Output Mode: $OUTPUT_MODE"
echo "Format Template: $OUTPUT_FORMAT_FILE"
echo "Victim: http://${VICTIM_HOST}:${VICTIM_PORT}"
echo "Result File: $RESULT_FILE"
echo "=========================================="

# Verify prompt file exists
if [[ ! -f "$PROMPT_FILE" ]]; then
    echo "ERROR: Prompt file not found: $PROMPT_FILE"
    exit 1
fi

# Read prompt
PROMPT=$(cat "$PROMPT_FILE")

# Add victim target information to prompt
PROMPT="Target: http://${VICTIM_HOST}:${VICTIM_PORT}

${PROMPT}"

# Load output format instructions from template file
if [[ ! -f "$OUTPUT_FORMAT_FILE" ]]; then
    echo "ERROR: Output format file not found: $OUTPUT_FORMAT_FILE"
    exit 1
fi

# Read template and replace {{RESULT_FILE}} placeholder
FORMAT_INSTRUCTION=$(cat "$OUTPUT_FORMAT_FILE" | sed "s|{{RESULT_FILE}}|${RESULT_FILE}|g")
FORMAT_INSTRUCTION="

${FORMAT_INSTRUCTION}"

FULL_PROMPT="${PROMPT}${FORMAT_INSTRUCTION}"

# Wait for metrics proxy (if configured)
PROXY_URL="${ANTHROPIC_BASE_URL:-${OPENAI_BASE_URL:-$GOOGLE_GEMINI_BASE_URL}}"
if [[ -n "$PROXY_URL" ]]; then
    echo "Waiting for metrics proxy at $PROXY_URL..."
    PROXY_RETRIES=0
    PROXY_MAX_RETRIES=30
    while ! curl -sf "${PROXY_URL}/health" > /dev/null 2>&1; do
        PROXY_RETRIES=$((PROXY_RETRIES + 1))
        if [[ $PROXY_RETRIES -ge $PROXY_MAX_RETRIES ]]; then
            echo "WARNING: Metrics proxy not reachable after $PROXY_MAX_RETRIES attempts"
            echo "Continuing without metrics tracking..."
            break
        fi
        echo "  Attempt $PROXY_RETRIES/$PROXY_MAX_RETRIES..."
        sleep 2
    done
    if [[ $PROXY_RETRIES -lt $PROXY_MAX_RETRIES ]]; then
        echo "Metrics proxy is ready!"
    fi
fi

# Wait for victim to be reachable
echo "Waiting for victim to be reachable..."
MAX_RETRIES=30
RETRY_COUNT=0
while ! curl -sf "http://${VICTIM_HOST}:${VICTIM_PORT}" > /dev/null 2>&1; do
    RETRY_COUNT=$((RETRY_COUNT + 1))
    if [[ $RETRY_COUNT -ge $MAX_RETRIES ]]; then
        echo "ERROR: Victim not reachable after $MAX_RETRIES attempts"
        exit 1
    fi
    echo "  Attempt $RETRY_COUNT/$MAX_RETRIES..."
    sleep 2
done
echo "Victim is reachable!"

# Execute based on agent type
echo "Starting attack with $AGENT_TYPE agent..."
echo ""

# Create output directory (may not exist if not volume-mounted)
# Note: Logs are captured via LiteLLM proxy, not local files
mkdir -p /results

# Create empty result file (model will write to it)
touch "$RESULT_FILE"

# Execute agent and capture output/exit code
set +e  # Don't exit on error

case "$AGENT_TYPE" in
    codex)
        # OpenAI Codex CLI with GPT-5.2-Codex model
        # Login with API key first
        echo "$OPENAI_API_KEY" | codex login --with-api-key
        # Using exec subcommand for non-interactive execution
        # --model gpt-5.2-codex: Use GPT-5.2 Codex model
        # --yolo: Bypass all approvals and sandbox (for containerized execution)
        # --skip-git-repo-check: Skip git repository check for containerized execution
        # Conversation logs captured via LiteLLM proxy (metrics/logs/usage.jsonl)
        OUTPUT=$(codex exec --model gpt-5.2-codex --yolo --skip-git-repo-check "$FULL_PROMPT" 2>&1)
        EXIT_CODE=$?
        ;;
    claude)
        # Claude Code CLI with Opus 4.5 model
        # --model: Use Claude Opus 4.5 for state-of-the-art software engineering
        # Using print mode for non-interactive execution
        # Conversation logs captured via LiteLLM proxy (metrics/logs/usage.jsonl)
        OUTPUT=$(claude --model claude-opus-4-5-20251101 --print --dangerously-skip-permissions "$FULL_PROMPT" 2>&1)
        EXIT_CODE=$?
        ;;
    gemini)
        # Gemini CLI with Gemini 3 Pro model
        # --model gemini-3-pro: Use Gemini 3 Pro for complex reasoning
        # -p: Non-interactive mode, --yolo: Auto-approve tool calls
        # GEMINI_API_KEY env var is set by docker-compose
        # Conversation logs captured via LiteLLM proxy (metrics/logs/usage.jsonl)
        OUTPUT=$(gemini --model gemini-3-pro-preview -p "$FULL_PROMPT" --yolo 2>&1)
        EXIT_CODE=$?
        ;;
    *)
        echo "ERROR: Unknown agent type: $AGENT_TYPE"
        exit 1
        ;;
esac

set -e  # Re-enable exit on error

# Check for limit exceeded (HTTP 429 from proxy)
if echo "$OUTPUT" | grep -q "limit_exceeded"; then
    echo ""
    echo "=========================================="
    echo "LIMIT REACHED - Agent terminated gracefully"
    echo "=========================================="
    # Extract limit details from error message
    echo "$OUTPUT" | grep -o '"message":"[^"]*"' | sed 's/"message":"//;s/"$//' || true
    echo ""
    echo "Full output:"
    echo "$OUTPUT"
    echo ""
    echo "=========================================="
    echo "Results saved to: $RESULT_FILE"
    echo "Conversation logs: metrics/logs/usage.jsonl (via LiteLLM proxy)"
    echo "=========================================="
    exit 0  # Exit with success code (intentional termination)
fi

# Print output for normal execution
echo "$OUTPUT"

# Fallback: if agent didn't write to file, save stdout as report
if [[ ! -s "$RESULT_FILE" ]]; then
    echo "[Fallback] Agent did not write to file, saving stdout..."
    echo "$OUTPUT" > "$RESULT_FILE"
fi

# Exit with original exit code for non-limit errors
if [[ $EXIT_CODE -ne 0 ]]; then
    echo ""
    echo "=========================================="
    echo "Agent exited with code: $EXIT_CODE"
    echo "=========================================="
    exit $EXIT_CODE
fi

echo ""
echo "=========================================="
echo "Attack completed successfully!"
echo "Results saved to: $RESULT_FILE"
echo "Conversation logs: metrics/logs/usage.jsonl (via LiteLLM proxy)"
echo "=========================================="
